{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte I. \n",
    "\n",
    "Programa y valida el Clasificador Naïve Bayes, valídalo con 3 datasets (Iris, Wine y Digits)  y los siguientes métodos de validación. \n",
    "\n",
    "Hold-Out 70/30 estratificado\n",
    "10-Fold Cross-Validation estratificado\n",
    "Leave-One-Out.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasos a realizar en la practica:\n",
    "\n",
    "Implementar el clasificador Naive Bayes.\n",
    "\n",
    "Validar el modelo en cada dataset con:\n",
    "Hold-Out (70/30 estratificado).\n",
    "10-Fold Cross-Validation estratificado.\n",
    "Leave-One-Out (LOO).\n",
    "\n",
    "Analizar los resultados y justificar el valor más adecuado de k (si aplica)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados para el Dataset: Iris\n",
      "Hold-Out Accuracy: 0.9111\n",
      "Hold-Out Confusion Matrix:\n",
      "[[15  0  0]\n",
      " [ 0 14  1]\n",
      " [ 0  3 12]]\n",
      "10-Fold CV Accuracy: 0.9533\n",
      "Leave-One-Out Accuracy: 0.9533\n",
      "\n",
      "Resultados para el Dataset: Wine\n",
      "Hold-Out Accuracy: 1.0000\n",
      "Hold-Out Confusion Matrix:\n",
      "[[18  0  0]\n",
      " [ 0 21  0]\n",
      " [ 0  0 15]]\n",
      "10-Fold CV Accuracy: 0.9778\n",
      "Leave-One-Out Accuracy: 0.9775\n",
      "\n",
      "Resultados para el Dataset: Digits\n",
      "Hold-Out Accuracy: 0.8222\n",
      "Hold-Out Confusion Matrix:\n",
      "[[49  1  0  0  3  1  0  0  0  0]\n",
      " [ 0 46  2  0  0  0  1  0  6  0]\n",
      " [ 0  7 34  0  1  0  0  0 11  0]\n",
      " [ 0  2  1 37  0  1  0  2 11  1]\n",
      " [ 0  1  0  0 45  0  1  5  2  0]\n",
      " [ 0  1  0  0  0 50  0  2  0  2]\n",
      " [ 0  1  0  0  0  0 53  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 53  0  0]\n",
      " [ 0 11  1  0  0  1  0  1 38  0]\n",
      " [ 0  4  1  0  0  0  0  6  4 39]]\n",
      "10-Fold CV Accuracy: 0.8425\n",
      "Leave-One-Out Accuracy: 0.8408\n",
      "\n",
      "Resumen de Resultados:\n",
      "\n",
      "Dataset: Iris\n",
      "Hold-Out -> Accuracy: 0.9111\n",
      "Confusion Matrix:\n",
      "[[15  0  0]\n",
      " [ 0 14  1]\n",
      " [ 0  3 12]]\n",
      "10-Fold CV -> Accuracy: 0.9533\n",
      "Leave-One-Out -> Accuracy: 0.9533\n",
      "\n",
      "Dataset: Wine\n",
      "Hold-Out -> Accuracy: 1.0000\n",
      "Confusion Matrix:\n",
      "[[18  0  0]\n",
      " [ 0 21  0]\n",
      " [ 0  0 15]]\n",
      "10-Fold CV -> Accuracy: 0.9778\n",
      "Leave-One-Out -> Accuracy: 0.9775\n",
      "\n",
      "Dataset: Digits\n",
      "Hold-Out -> Accuracy: 0.8222\n",
      "Confusion Matrix:\n",
      "[[49  1  0  0  3  1  0  0  0  0]\n",
      " [ 0 46  2  0  0  0  1  0  6  0]\n",
      " [ 0  7 34  0  1  0  0  0 11  0]\n",
      " [ 0  2  1 37  0  1  0  2 11  1]\n",
      " [ 0  1  0  0 45  0  1  5  2  0]\n",
      " [ 0  1  0  0  0 50  0  2  0  2]\n",
      " [ 0  1  0  0  0  0 53  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 53  0  0]\n",
      " [ 0 11  1  0  0  1  0  1 38  0]\n",
      " [ 0  4  1  0  0  0  0  6  4 39]]\n",
      "10-Fold CV -> Accuracy: 0.8425\n",
      "Leave-One-Out -> Accuracy: 0.8408\n"
     ]
    }
   ],
   "source": [
    "# Importar librerías necesarias\n",
    "from sklearn.datasets import load_iris, load_wine, load_digits\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "\n",
    "# Función para evaluar Naive Bayes\n",
    "def evaluate_naive_bayes(X, y, dataset_name):\n",
    "    print(f\"\\nResultados para el Dataset: {dataset_name}\")\n",
    "    results = {}\n",
    "\n",
    "    # Clasificador Naive Bayes\n",
    "    nb = GaussianNB()\n",
    "\n",
    "    # Hold-Out 70/30 estratificado\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "    nb.fit(X_train, y_train)\n",
    "    y_pred = nb.predict(X_test)\n",
    "    acc_holdout = accuracy_score(y_test, y_pred)\n",
    "    cm_holdout = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Hold-Out Accuracy: {acc_holdout:.4f}\")\n",
    "    print(f\"Hold-Out Confusion Matrix:\\n{cm_holdout}\")\n",
    "\n",
    "    # 10-Fold Cross-Validation estratificado\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        nb.fit(X_train, y_train)\n",
    "        y_pred = nb.predict(X_test)\n",
    "        cv_scores.append(accuracy_score(y_test, y_pred))\n",
    "    acc_cv = np.mean(cv_scores)\n",
    "    print(f\"10-Fold CV Accuracy: {acc_cv:.4f}\")\n",
    "\n",
    "    # Leave-One-Out\n",
    "    loo = LeaveOneOut()\n",
    "    loo_scores = []\n",
    "    for train_idx, test_idx in loo.split(X):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        nb.fit(X_train, y_train)\n",
    "        y_pred = nb.predict(X_test)\n",
    "        loo_scores.append(accuracy_score(y_test, y_pred))\n",
    "    acc_loo = np.mean(loo_scores)\n",
    "    print(f\"Leave-One-Out Accuracy: {acc_loo:.4f}\")\n",
    "\n",
    "    # Guardar resultados\n",
    "    results['Hold-Out'] = {\"Accuracy\": acc_holdout, \"Confusion Matrix\": cm_holdout}\n",
    "    results['10-Fold CV'] = {\"Accuracy\": acc_cv}\n",
    "    results['Leave-One-Out'] = {\"Accuracy\": acc_loo}\n",
    "    return results\n",
    "\n",
    "# Cargar datasets y evaluar Naive Bayes\n",
    "datasets = {\n",
    "    \"Iris\": load_iris(),\n",
    "    \"Wine\": load_wine(),\n",
    "    \"Digits\": load_digits()\n",
    "}\n",
    "\n",
    "all_results = {}\n",
    "for name, data in datasets.items():\n",
    "    X, y = data.data, data.target\n",
    "    results = evaluate_naive_bayes(X, y, name)\n",
    "    all_results[name] = results\n",
    "\n",
    "# Mostrar resumen de resultados\n",
    "print(\"\\nResumen de Resultados:\")\n",
    "for dataset_name, dataset_results in all_results.items():\n",
    "    print(f\"\\nDataset: {dataset_name}\")\n",
    "    for method, metrics in dataset_results.items():\n",
    "        print(f\"{method} -> Accuracy: {metrics['Accuracy']:.4f}\")\n",
    "        if method == 'Hold-Out':\n",
    "            print(f\"Confusion Matrix:\\n{metrics['Confusion Matrix']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
